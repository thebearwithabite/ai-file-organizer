# ğŸ¤– AI File Organizer
## The Ultimate ADHD-Friendly Intelligent File Management System

<div align="center">

![AI File Organizer Banner](https://img.shields.io/badge/AI%20File%20Organizer-Revolutionary%20File%20Management-blue?style=for-the-badge&logo=robot)

[![Python](https://img.shields.io/badge/python-3.11+-brightgreen.svg?style=flat-square&logo=python)](https://www.python.org/)
[![macOS](https://img.shields.io/badge/platform-macOS-lightgrey.svg?style=flat-square&logo=apple)](https://www.apple.com/macos/)
[![License](https://img.shields.io/badge/license-MIT-blue.svg?style=flat-square)](LICENSE)
[![ADHD Friendly](https://img.shields.io/badge/ADHD-Friendly%20Design-purple.svg?style=flat-square&logo=accessibility)](https://github.com/thebearwithabite/ai-file-organizer)

**Transform your chaotic file collections into intelligently organized, searchable libraries with AI that understands your content, learns your patterns, and includes powerful safety features.**

[ğŸš€ Quick Start](#-quick-start) â€¢ [ğŸ“– Documentation](#-documentation) â€¢ [ğŸ¯ Features](#-features) â€¢ [ğŸ§  For ADHD Users](#-adhd-optimized-design) â€¢ [ğŸ¤ Contributing](#-contributing)

</div>

---

## ğŸŒŸ What Makes This Revolutionary

This isn't just file organization - it's an **AI ecosystem** that learns, adapts, and evolves with your workflow while maintaining ADHD-friendly simplicity.

```mermaid
graph TB
    A[ğŸ—‚ï¸ Chaotic Files] --> B[ğŸ¤– AI File Organizer v2.1]
    B --> C[ğŸ§  Semantic Understanding]
    B --> D[â™»ï¸ Safe File Recycling]
    B --> E[ğŸ›¡ï¸ Bulletproof Duplicate Detection]
    B --> F[ğŸ¯ 85% Confidence Threshold]
    B --> G[âš¡ Emergency Storage Recovery]
    B --> H[ğŸ‘ï¸ Computer Vision & OCR]
    
    C --> I[ğŸ“š Intelligent Library]
    D --> J[ğŸ›¡ï¸ Zero "Oops!" Moments]
    E --> K[ğŸ’¾ Automatic Storage Optimization]
    F --> L[â“ Smart Questions Only]
    G --> M[ğŸš¨ Crisis Management]
    H --> N[ğŸ–¼ï¸ Visual Content Intelligence]
    
    I --> O[âœ¨ Perfect Organization]
    J --> O
    K --> O
    L --> O
    M --> O
    N --> O
```

### ğŸ¯ **Perfect For**

<table>
<tr>
<td width="33%">

**ğŸ§  ADHD Professionals**
- ğŸ›¡ï¸ Safe file recycling system
- â™»ï¸ 7-day undo window for all moves
- ğŸ¯ Reduces decision anxiety
- ğŸ¤” 85% confidence threshold prevents overwhelm
- ğŸ“Š Real-time duplicate detection

</td>
<td width="33%">

**ğŸ¬ Entertainment Industry**
- ğŸ“„ Contract organization
- ğŸ‘¤ Client file management
- ğŸ¨ Creative project tracking
- ğŸ—‘ï¸ Bulletproof duplicate detection
- ğŸ’¾ Emergency storage management

</td>
<td width="33%">

**ğŸ¨ Creative Professionals**
- ğŸ§  Semantic content understanding
- ğŸ“§ Email integration for unified search
- ğŸ‘ï¸ Computer vision & OCR for images
- ğŸ·ï¸ Smart naming protocols
- âš¡ Automatic storage optimization
- ğŸ” Background monitoring

</td>
</tr>
</table>  

---

## ğŸš€ Quick Start

### Installation
```bash
# Clone the repository
git clone https://github.com/thebearwithabite/ai-file-organizer.git
cd ai-file-organizer

# Install dependencies
pip install -r requirements.txt

# Set your OpenAI API key (for classification only - no files sent to API)
export OPENAI_API_KEY="your-api-key-here"
```

### First Run - Emergency Storage Recovery (if needed)
```bash
# Check storage space
df -h

# Emergency cleanup if critically low on space
python system_storage_cleanup.py --execute --docker-only  # Frees ~16GB

# Move ghost directories to staging for later organization
# (Check for any CONTENT_LIBRARY_MASTER or similar directories)
```

### Core File Organization
```bash
# Start with safe file recycling (ADHD-friendly - can undo for 7 days)
python interactive_organizer.py organize --dry-run  # Preview first
python interactive_organizer.py organize --live     # Actually organize

# Index your existing files for semantic search
python vector_librarian.py

# Try semantic search
python enhanced_librarian.py search "important contracts" --mode semantic

# Check safe recycling status
python safe_file_recycling.py --status
```

### Duplicate Detection & Storage Optimization
```bash
# Run bulletproof duplicate detection
python safe_deduplication.py --folder "/Users/user/Downloads" --execute

# Check deduplication database
python deduplication_system.py --status

# Monitor real-time duplicate detection
python background_monitor.py  # Catches duplicates as they're created
```

---


---

## ğŸ¬ How It Works

### **Before AI Organizer:**
```
Downloads/
â”œâ”€â”€ contract_final_v2.pdf
â”œâ”€â”€ IMPORTANT_DOC.docx  
â”œâ”€â”€ email_export.txt
â””â”€â”€ random_notes.md
```

### **After AI Organizer:**
```
01_ACTIVE_PROJECTS/
â”œâ”€â”€ Entertainment_Industry/
â”‚   â””â”€â”€ Current_Contracts/
â”‚       â””â”€â”€ 2025-08-21_ENT_ClientName_Management-Agreement_v2.pdf
â”œâ”€â”€ Business_Operations/
â”‚   â””â”€â”€ Financial_Records/
â”‚       â””â”€â”€ 2025-08-21_BUS_General_Commission-Report_v1.docx
â””â”€â”€ Creative_Production/
    â””â”€â”€ 2025-08-21_CRE_General_Notes_v1.md

04_METADATA_SYSTEM/
â””â”€â”€ comprehensive_index.xlsx  # Searchable database of everything
```

**Plus:** Semantic search finds things like *"payment terms"* even when the document says *"compensation structure"*!

---

## ğŸ§  Revolutionary Features Deep Dive

### **ğŸ›¡ï¸ Safe File Recycling System (Zero "Oops!" Moments)**
Every file move goes through a safe recycling system first - eliminating anxiety about permanent mistakes.

```bash
â™»ï¸  File Recycling Process:
   1. File moved to temporary recycling directory
   2. Full audit trail maintained in SQLite database
   3. 7-day undo window for all operations
   4. Simple restore commands: python safe_file_recycling.py --restore filename
   5. Automatic cleanup after retention period

ğŸ“Š Recycling Status:
   Files in recycling: 23
   Total space: 156.7 MB
   Oldest file: 3 days ago
   Can restore: All files
```

### **ğŸ—‘ï¸ Bulletproof Duplicate Detection**
Two-tier hashing system catches duplicates with 100% safety and actually deletes them.

```bash
ğŸ” Duplicate Detection Process:
   1. Quick MD5 hash for real-time detection
   2. Secure SHA-256 hash for safe deletion
   3. Smart pattern recognition ("filename (1).ext", "filename copy.ext")
   4. Safety scoring based on file age, location, patterns
   5. Automatic deletion of confirmed duplicates

ğŸ“Š Recent Scan Results:
   Files scanned: 1,247
   Duplicates found: 77
   Space freed: 269.6 MB
   Safety score: 100% (all safe to delete)
```

### **âš¡ Emergency Storage Recovery**
Critical storage space management when your drive is nearly full.

```bash
ğŸš¨ Storage Crisis Management:
   Docker cleanup: 16.2 GB freed
   Cache cleanup: 2.3 GB freed  
   Ghost directories: 6.7 GB moved to staging
   Duplicate removal: 269.6 MB freed
   Total recovered: 25.5 GB
```

### **ğŸ¤” Interactive Classification with 85% Confidence Rule**
- Shows you file content before asking questions
- Only asks when genuinely uncertain (< 85% confidence) 
- Learns your preferences to reduce future questions
- ADHD-friendly: Clear choices, no overwhelming options

```bash
ğŸ“„ Analyzing: client_agreement.pdf
ğŸ” Content Preview:
   "This agreement between Company and Client Name covers 
    exclusive representation for television and film..."

ğŸ¤– Initial AI Analysis:
   Suggested Category: Entertainment Industry (72% confidence)
   
â“ CLASSIFICATION QUESTION
   Based on the content above:
   Should this entertainment document be filed under:
   1. Current active projects
   2. Business operations 
   3. Archived contracts

âœ… You chose: Current active projects
   Confidence updated: 95% âœ…
   â™»ï¸  File recycled safely (can undo for 7 days)
```

### **ğŸ·ï¸ Smart File Naming Protocol**
Automatically generates meaningful filenames using the format:
`YYYY-MM-DD_PROJECT_CLIENT_CONTENT-TYPE_vN.ext`

**Examples:**
- `client_stuff.pdf` â†’ `2025-08-21_ENT_ClientName_Management-Agreement_v1.pdf`
- `commission_report.xlsx` â†’ `2025-08-21_BUS_Internal_Commission-Report_v1.xlsx`

### **ğŸ§  Vector Database with Smart Chunking**
- **Contracts**: Chunked by sections (compensation, terms, exclusivity)
- **Scripts**: Chunked by scenes and dialogue  
- **Emails**: Separate headers from body content
- **Business docs**: Organized by topics and sections

### **ğŸ”„ Background Monitoring with Real-Time Duplicate Detection**
```bash
ğŸ“ Directory Monitoring:
   âœ… Staging: Processes immediately (organized files)
   âœ… Downloads: 7-day wait (won't disrupt active work)  
   âœ… Desktop: 7-day wait (ADHD-friendly)
   âœ… Documents: Processes regularly
   âœ… Email: Auto-indexes new messages
   âœ… Duplicates: Caught and removed in real-time
```

---

## ğŸš€ Advanced Usage

### **ğŸ” Search Modes**
```bash
# Fast keyword search
python enhanced_librarian.py search "Client Name" --mode fast

# Semantic AI search (understands meaning)  
python enhanced_librarian.py search "payment terms" --mode semantic

# Auto-chooses best approach
python enhanced_librarian.py search "creative collaboration" --mode auto
```

### **â™»ï¸ Safe File Operations**
```bash
# Organize with safe recycling (default - ADHD-friendly)
python interactive_organizer.py organize --live

# Use direct moves (legacy behavior)
python interactive_organizer.py organize --live --direct-moves

# Check what's in recycling
python safe_file_recycling.py --list

# Restore a specific file
python safe_file_recycling.py --restore "filename_20250906_143022.pdf"

# Check recycling status
python safe_file_recycling.py --status
```

### **ğŸ—‘ï¸ Duplicate Management**
```bash
# Bulletproof duplicate detection and removal
python safe_deduplication.py --folder "/Users/user/Downloads" --execute

# Check duplicate database status
python deduplication_system.py --status

# Manual duplicate analysis (safe mode)
python downloads_specific_deduplication.py --dry-run
```

### **âš¡ Storage Management**
```bash
# Emergency storage cleanup
python system_storage_cleanup.py --execute --docker-only

# Full system cleanup (more aggressive)
python system_storage_cleanup.py --execute --full

# Check what cleanup would do
python system_storage_cleanup.py --dry-run
```

### **ğŸ”„ Background Monitoring**
```bash
# Start auto-monitoring with duplicate detection
python monitor_control.py start

# Check monitoring status
python monitor_control.py status  

# Manual scan of specific folder
python monitor_control.py scan /Users/user/Downloads
```

### **ğŸ¤” Interactive Organization**
```bash
# Organize with content previews and questions
python interactive_organizer.py organize --dry-run  # Preview first
python interactive_organizer.py organize --live     # Execute

# Quick organize specific folder
python interactive_organizer.py quick "/Users/user/Downloads" --live

# Test single file classification  
python interactive_organizer.py file "/path/to/file.pdf" --live
```

---

## ğŸ“Š System Architecture

```
ğŸ—‚ï¸  AI File Organizer v2.1/
â”œâ”€â”€ ğŸ§  Vector Database (ChromaDB)         # Semantic search engine
â”œâ”€â”€ ğŸ“§ Email Integration (.emlx files)    # macOS Mail integration  
â”œâ”€â”€ ğŸ“„ Document Processing               # PDFs, DOCX, scripts
â”œâ”€â”€ ğŸ‘ï¸ Computer Vision & OCR             # Image processing and text extraction
â”œâ”€â”€ ğŸ” Smart Search Interface           # Natural language queries
â”œâ”€â”€ ğŸ AppleScript GUI                  # Native macOS integration
â”œâ”€â”€ ğŸ¤” Interactive Classification       # Asks questions until 85% confident
â”œâ”€â”€ ğŸ·ï¸  Smart Naming Protocol           # Auto-generates meaningful names
â”œâ”€â”€ â™»ï¸  Safe File Recycling             # 7-day undo for all operations
â”œâ”€â”€ ğŸ—‘ï¸  Bulletproof Duplicate Detection # Two-tier hashing system
â”œâ”€â”€ âš¡ Emergency Storage Recovery        # Critical space management
â””â”€â”€ ğŸ”„ Background Monitor               # Real-time monitoring & duplicate detection
```

### **Core Components:**
- **`enhanced_librarian.py`** - Main search and organization interface
- **`vector_librarian.py`** - Semantic search with ChromaDB
- **`interactive_classifier.py`** - AI classification with user feedback
- **`interactive_organizer.py`** - Safe organization with recycling integration
- **`safe_file_recycling.py`** - ADHD-friendly undo system for all file moves
- **`deduplication_system.py`** - Real-time duplicate detection with two-tier hashing
- **`safe_deduplication.py`** - Bulletproof duplicate removal with safety scoring
- **`system_storage_cleanup.py`** - Emergency storage space recovery
- **`background_monitor.py`** - Auto-monitoring and real-time duplicate detection
- **`file_naming_protocol.py`** - Intelligent filename generation
- **`email_extractor.py`** - macOS Mail integration

---

## ğŸ¯ ADHD-Optimized Design

**Why this system is revolutionary for ADHD brains:**

âœ… **Zero "Oops!" Anxiety** - Safe recycling system lets you undo ANY file move for 7 days  
âœ… **No decision paralysis** - System only asks when genuinely uncertain (85% confidence rule)  
âœ… **Learns your patterns** - Reduces cognitive load over time  
âœ… **7-day waiting period** - Won't interfere with active Downloads/Desktop work  
âœ… **Automatic duplicate removal** - Frees mental energy from "did I save this already?" worry  
âœ… **Emergency storage recovery** - Prevents panic when drive fills up  
âœ… **Binary choices** - Never overwhelms with too many options  
âœ… **Visual previews** - See content before making decisions  
âœ… **Forgiving search** - Finds things even with imprecise queries  
âœ… **Real-time protection** - Background monitoring catches problems immediately  

**Real ADHD Benefits:**
- **Eliminate filing anxiety** - Every move can be undone, removing fear of making mistakes
- **Stop duplicate accumulation** - Automatic detection prevents the "1000 copies" problem
- **Find things without perfect organization** - Semantic search understands your intent
- **Reduce storage stress** - Emergency cleanup prevents drive-full panic
- **Build searchable knowledge base effortlessly** - Just save files, system handles the rest
- **Never lose important documents** - Everything is tracked and recoverable

---

## ğŸ“ˆ Performance & Scaling

- **Processing Speed**: ~100-500 files per hour (depending on content)
- **Library Size**: Tested with 10,000+ file libraries
- **Memory Usage**: ~200MB for typical usage
- **Vector Database**: Grows ~10-50MB per 1,000 documents
- **Search Speed**: Sub-2 second semantic search results
- **Duplicate Detection**: ~1,247 files scanned in under 30 seconds
- **Storage Recovery**: Up to 25GB+ freed in emergency situations
- **Recycling Overhead**: <1% storage penalty for 7-day safety
- **Real-time Monitoring**: <10MB memory overhead for background processes

---

## ğŸ›¡ï¸ Privacy & Security  

- **100% Local Processing** - All AI analysis happens on your machine
- **No Cloud Uploads** - Your files never leave your computer
- **API Usage** - Only sends text descriptions to OpenAI, never file content
- **Open Source** - Fully auditable, no hidden data collection

---

## ğŸ”§ Technical Requirements

### **Minimum:**
- macOS 10.15+ (Catalina or newer)
- Python 3.8+ 
- 8GB RAM
- 2GB storage space

### **Recommended:**
- macOS 12+ (Monterey or newer) 
- Python 3.10+
- 16GB RAM
- M1/M2 Apple Silicon (faster embedding generation)

### **Dependencies:**
```bash
# Core AI/ML
sentence-transformers>=2.2.0
chromadb>=0.4.0
numpy>=1.21.0

# Document processing  
PyPDF2>=3.0.1
python-docx>=1.2.0
lxml>=6.0.0

# System integration (built-in Python modules used):
# - sqlite3 (duplicate detection database)
# - hashlib (file hashing)
# - pathlib (file operations)
# - shutil (safe file moves)
# - watchdog (background monitoring)
```

---

## ğŸ”§ Detailed System Components & Methods

### **ğŸ›¡ï¸ Safe File Recycling System (`safe_file_recycling.py`)**

**Core Methods:**
- `recycle_file(file_path, destination_path, operation_type, reason)` - Moves file to recycling directory instead of direct organization
- `restore_file(recycled_filename)` - Restores file from recycling to original or specified location
- `list_recycled_files()` - Shows all files in recycling with metadata and restore options
- `cleanup_expired()` - Automatically removes files older than retention period
- `get_recycling_status()` - Returns statistics about recycled files and storage usage

**Database Schema:**
```sql
recycled_files (
    id INTEGER PRIMARY KEY,
    original_path TEXT,
    recycled_path TEXT, 
    destination_path TEXT,
    recycled_time TEXT,
    operation_type TEXT,  -- "organize", "duplicate", "manual"
    can_restore BOOLEAN,
    file_size INTEGER,
    reason TEXT,
    restored BOOLEAN DEFAULT FALSE
)
```

**Safety Features:**
- 7-day default retention period (configurable)
- Complete audit trail of all file operations
- Unique timestamped filenames prevent conflicts
- SQLite database for reliable metadata storage
- Automatic cleanup with user confirmation

---

### **ğŸ—‘ï¸ Bulletproof Duplicate Detection (`deduplication_system.py`, `safe_deduplication.py`)**

**Two-Tier Hashing System:**
- `calculate_quick_hash(file_path)` - MD5 hash for fast initial comparison
- `calculate_secure_hash(file_path)` - SHA-256 hash for confirmed deletion safety
- `detect_new_duplicate(file_path)` - Real-time duplicate detection for new files
- `find_duplicate_groups()` - Groups files by hash with metadata analysis

**Safety Scoring Methods:**
- `calculate_safety_score(file_path, duplicate_group)` - Multi-factor safety analysis
- `analyze_duplicate_patterns()` - Recognizes common patterns like "filename (1).ext"
- `check_protected_paths()` - Prevents deletion from critical system directories
- `verify_file_accessibility()` - Ensures files can be safely deleted

**Smart Pattern Recognition:**
```python
safe_duplicate_patterns = [
    r'.*\s\(\d+\)\..*',          # "filename (1).ext"
    r'.*\scopy\..*',             # "filename copy.ext" 
    r'Generated Image.*\.jpeg',   # ChatGPT generated images
    r'.*_\d{8}_\d{6}\..*'        # Timestamped duplicates
]
```

**Database Schema:**
```sql
file_hashes (
    id INTEGER PRIMARY KEY,
    file_path TEXT UNIQUE,
    quick_hash TEXT,
    secure_hash TEXT,
    file_size INTEGER,
    last_modified REAL,
    duplicate_group_id TEXT,
    safety_score REAL,
    can_delete BOOLEAN
)
```

---

### **âš¡ Emergency Storage Recovery (`system_storage_cleanup.py`)**

**Core Cleanup Methods:**
- `clean_docker_data()` - Safely removes Docker containers, images, and cache (~16GB typical)
- `clean_system_caches()` - Clears user and system cache directories
- `clean_google_drive_cache()` - Removes Google Drive local cache files
- `find_ghost_directories()` - Locates large directories that may have been forgotten
- `analyze_storage_usage()` - Provides detailed breakdown of disk usage by category

**Safety Mechanisms:**
- Checks if Docker is running before cleanup
- Creates backup lists of removed items
- Dry-run mode shows what would be cleaned without executing
- User confirmation for potentially destructive operations
- Detailed logging of all cleanup actions

**Emergency Mode Features:**
- Automatic detection of critically low storage (< 5GB)
- Priority-based cleanup (caches first, then optional data)
- Real-time progress reporting during large operations
- Recovery estimation before execution

---

### **ğŸ”„ Real-Time Background Monitoring (`background_monitor.py`)**

**Monitoring Methods:**
- `watch_directory(path, callback)` - File system event monitoring
- `process_new_file(file_path)` - Handles newly created files
- `check_for_duplicates_realtime(file_path)` - Immediate duplicate detection
- `queue_for_organization(file_path)` - Adds files to organization queue
- `update_vector_index(file_path)` - Maintains search index in real-time

**Event Handling:**
- File creation events trigger duplicate checking
- File modification updates vector database
- Directory changes trigger re-indexing
- Handles batch operations efficiently

**ADHD-Friendly Features:**
- 7-day grace period for Desktop/Downloads (won't disrupt active work)
- Immediate processing for organized directories (staging areas)
- Progress notifications without being overwhelming
- Configurable monitoring sensitivity

---

### **ğŸ§  Enhanced Interactive Classification (`interactive_classifier.py`)**

**Classification Methods:**
- `classify_with_questions(file_path, content)` - Main classification with user interaction
- `analyze_content_confidence(content)` - Determines if questions are needed (85% rule)
- `generate_smart_questions(classification_result)` - Creates contextual questions
- `learn_from_feedback(user_choice, context)` - Improves future classifications
- `get_classification_confidence(features)` - Calculates certainty percentage

**Learning System:**
- Tracks user preferences in local database
- Adjusts confidence thresholds based on patterns
- Reduces questions over time as system learns
- Context-aware question generation

**Question Types:**
- Binary choices (A or B) to prevent overwhelm
- Content-based context provided before questions
- Confidence level shown for transparency
- Reasoning explanation for AI suggestions

---

### **ğŸ“Š Vector Search & Semantic Understanding (`vector_librarian.py`)**

**Semantic Processing:**
- `chunk_document_intelligently(file_path, content)` - Context-aware content chunking
- `generate_embeddings(text_chunks)` - Creates semantic vectors for search
- `semantic_search(query, mode)` - Natural language search across all content
- `hybrid_search(query)` - Combines keyword and semantic search

**Smart Chunking Strategies:**
- **Contracts**: Sections like compensation, terms, exclusivity
- **Scripts**: Scene and dialogue boundaries
- **Emails**: Separate headers, body, and signatures  
- **Academic**: Preserves abstract, introduction, conclusion structure

**Search Modes:**
- `fast` - Keyword matching for names, dates, specific terms
- `semantic` - AI understanding of concepts and meaning
- `auto` - Intelligently chooses best approach based on query
- `hybrid` - Combines both for comprehensive results

---

### **ğŸ·ï¸ Intelligent File Naming (`file_naming_protocol.py`)**

**Naming Methods:**
- `generate_smart_filename(file_path, classification, content)` - Creates meaningful names
- `extract_date_context(content, file_stats)` - Determines appropriate date
- `identify_client_project(content)` - Extracts relevant client/project information
- `determine_content_type(classification, content)` - Categorizes document type
- `ensure_unique_filename(proposed_name, directory)` - Handles naming conflicts

**Naming Convention:**
```
YYYY-MM-DD_PROJECT_CLIENT_CONTENT-TYPE_vN.ext

Examples:
2025-09-06_ENT_ClientName_Management-Agreement_v1.pdf
2025-09-06_BUS_Internal_Commission-Report_v1.xlsx
2025-09-06_CRE_Creative-Project_Meeting-Notes_v1.md
```

**Intelligence Features:**
- Extracts dates from content, not just file timestamps
- Recognizes client names and project contexts
- Maintains version numbering automatically
- Handles special characters and length limits
- Preserves important original information

---

### **ğŸ‘ï¸ Computer Vision & Image Processing (`classification_engine.py`, `query_interface.py`)**

**Image Recognition Capabilities:**
- `analyze_image_content(image_path)` - OCR text extraction from images
- `classify_image_type(image_path)` - Determines image category (photo, document scan, screenshot, etc.)
- `extract_metadata(image_path)` - EXIF data, dimensions, creation date
- `detect_document_images(image_path)` - Identifies scanned documents vs photos
- `process_screenshot_text(image_path)` - Extracts text from screenshots

**Supported Image Formats:**
```python
supported_formats = [
    '.jpg', '.jpeg',  # Standard photos
    '.png',          # Screenshots, graphics
    '.gif',          # Animated images
    '.bmp',          # Bitmap images
    '.tiff'          # High-quality scans
]
```

**Smart Image Classification:**
- **Document Scans**: Automatically routes to appropriate document categories
- **Screenshots**: Extracts UI text and categorizes by application context
- **Photos**: Organizes by date and detected content
- **Generated Images**: Recognizes AI-generated content (ChatGPT images, etc.)
- **Creative Assets**: Identifies graphics, logos, design files

**OCR Integration:**
```python
def extract_text_from_image(image_path):
    """
    Optical Character Recognition for:
    - Scanned contracts and documents
    - Screenshots with important text
    - Handwritten notes (limited support)
    - Business cards and forms
    - Receipt and invoice images
    """
```

**Computer Vision Search:**
```bash
# Search images by contained text
python enhanced_librarian.py search "contract signature" --include-images

# Find screenshots containing specific UI elements
python query_interface.py search "menu bar screenshot"

# Locate document scans by content
python enhanced_librarian.py search "tax documents" --mode semantic --images
```

**Visual Content Organization:**
- Automatic routing of scanned documents to appropriate business categories
- Screenshot organization by application and content context
- Photo organization by date and detected subjects
- Creative asset cataloging with project association
- Duplicate image detection using visual similarity hashing

---

## ğŸ¤ Contributing

We'd love your help making AI File Organizer even better!

### **Most Wanted Features:**
- [ ] Google Drive / Dropbox sync
- [ ] Windows/Linux support  
- [ ] Web interface for remote access
- [ ] Advanced genre-specific classification
- [ ] Collaborative library sharing
- [ ] More file format support

### **Bug Reports:**
Include your:
- Operating system and Python version
- File types you're organizing  
- Full error traceback
- Steps to reproduce

### **Development Setup:**
```bash
git clone https://github.com/yourusername/ai-file-organizer.git
cd ai-file-organizer
pip install -e ".[dev]"
python test_integration.py
```

---

## ğŸ“œ License

MIT License - see [LICENSE](LICENSE) for details.

**Built with â¤ï¸ for knowledge workers, creatives, and anyone who struggles with file organization.**

---

## ğŸŒŸ Star This Repo

If AI File Organizer transformed your workflow, **please star this repository!** â­

**Questions? Ideas? Success stories?**
- [Open an issue](https://github.com/yourusername/ai-file-organizer/issues)
- Email: [user@example.com](mailto:rt@papersthatdream.com)

---

*From digital chaos to intelligent organization. AI File Organizer learns, adapts, and grows with your unique workflow.*
